{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1461acc1-00d3-4cf0-8a2a-5f201a7840b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Project: Conway's Game of Life - CPU vs GPU Implementation \n",
    "\n",
    "## Resource Files \n",
    "\n",
    "The job submission scripts specifically configured for use on the University of Exeter ISCA HPC system are available [here](../intro_to_GPUs/zip_files/exeter_isca_slurm_submission_scripts.zip).  \n",
    "\n",
    "General-purpose job submission scripts, which can serve as a starting point for use on other HPC systems (with minor modifications required for this course), are available [here](../intro_to_GPUs/zip_files/slurm_submission_scripts.zip).  \n",
    "\n",
    "The Python scripts used in this course can be downloaded [here](../intro_to_GPUs/zip_files/scripts.zip).  \n",
    "\n",
    "All supplementary files required for the course are available [here](../intro_to_GPUs/zip_files/files.zip).  \n",
    "\n",
    "The presentation slides for this course can be accessed [here](../intro_to_GPUs/slides/GPU_Training_Day_Slides.pptx).\n",
    "\n",
    "## Overview \n",
    "In this project, we are going to see implementations of **Conway's Game of Life**, a classic cellular automaton in three ways: a pure python approach (to run on the CPU), a vectorised approach using NumPy (to run on the CPU) and then using CuPy (to run on the GPU). We'll also visualise the evolution of the Game of Life grid to see the computation in action. \n",
    "\n",
    "## What is Conway's Game of Life?\n",
    "\n",
    "It's a zero-player game devised by John Conway, where you have a grid of cells that live or die based on a few simple rules:\n",
    "- Each cell can be \"alive\" (1) or \"dead\" (0).\n",
    "- At each time step (generation), the following rules apply to every cell simultaneously:\n",
    "  - Any live cell with fewer than 2 live neighbours dies (underpopulation).\n",
    "  - Any live cell with 2 or 3 live neighbours lives on to the next generation (survival).\n",
    "  - Any live cell with more than 3 live neighbours dies (overpopulation).\n",
    "  - Any dead cell with exactly 3 live neighbours becomes a live cell (reproduction).\n",
    "- Neighbours are the 8 cells touching a given cell horizontally, vertically, or diagonally.\n",
    "- From these simple rules emerges a lot of interesting behaviour – stable patterns, oscillators, spaceships (patterns that move), etc. It's a good example of a grid-based simulation that can benefit from parallel computation because the state of each cell for the next generation can be computed independently (based on the current generation).\n",
    "\n",
    "## Visualisation of Game of Life\n",
    "\n",
    "To make this project more visually engaging, below is an **animated GIF** showing an example of a Game of Life simulation starting from a random initial configuration. White pixels represent live cells, and black pixels represent dead cells. You can see patterns forming, moving, and changing over time:\n",
    "An example evolution of Conway's Game of Life over a few generations (white = alive, black = dead).\n",
    "The animation demonstrates how random initial clusters of cells can evolve into interesting patterns. Notice some cells blink on and off or form moving patterns.\n",
    "\n",
    "The animation shows 50 timesteps on a 100x100 grid. \n",
    "\n",
    "![Conways Game of Life](files/game_of_life_figures/game_of_life_example.gif)\n",
    "\n",
    "\n",
    "## Implementations\n",
    "\n",
    "All of the implementation for the three different versions (Pure Python, NumPy and CuPy) are contained within the `.py` located at `content/game_of_life.py`. \n",
    "\n",
    "To run the different versions of the code, you can use:\n",
    "\n",
    "**Naïve Python Version**\n",
    "\n",
    "```bash\n",
    "python game_of_life.py run_life_naive --size 100 --timesteps 50\n",
    "```\n",
    "\n",
    "which will produce a file called `game_of_life_naive.gif`.\n",
    "\n",
    "**CPU-Vectorized Version**\n",
    "\n",
    "```bash\n",
    "python game_of_life.py run_life_numpy --size 100 --timesteps 50\n",
    "```\n",
    "\n",
    "which will produce a file called `game_of_life_cpu.gif`.\n",
    "\n",
    "**GPU-Accelerated Version**\n",
    "\n",
    "```bash\n",
    "python game_of_life.py run_life_cupy --size 100 --timesteps 50\n",
    "```\n",
    "\n",
    "which will produce a file called `game_of_life_gpu.gif`.\n",
    "\n",
    "## Naive Implementation\n",
    "\n",
    "The core computation that is being performed for the naive implementation is: \n",
    "\n",
    "```python\n",
    "def life_step_naive(grid: np.ndarray) -> np.ndarray:\n",
    "    N, M = grid.shape\n",
    "    new = np.zeros((N, M), dtype=int)\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            cnt = 0\n",
    "            for di in (-1, 0, 1):\n",
    "                for dj in (-1, 0, 1):\n",
    "                    if di == 0 and dj == 0:\n",
    "                        continue\n",
    "                    ni, nj = (i + di) % N, (j + dj) % M\n",
    "                    cnt += grid[ni, nj]\n",
    "            if grid[i, j] == 1:\n",
    "                new[i, j] = 1 if (cnt == 2 or cnt == 3) else 0\n",
    "            else:\n",
    "                new[i, j] = 1 if (cnt == 3) else 0\n",
    "    return new\n",
    "\n",
    "def simulate_life_naive(N: int, timesteps: int, p_alive: float = 0.2):\n",
    "    grid = np.random.choice([0, 1], size=(N, N), p=[1-p_alive, p_alive])\n",
    "    history = []\n",
    "    for _ in range(timesteps):\n",
    "        history.append(grid.copy())\n",
    "        grid = life_step_naive(grid)\n",
    "    return history\n",
    "```\n",
    "### Explanation \n",
    "\n",
    "There are a number of different reasons that the naive implementation runs slow, including: \n",
    "\n",
    "- **Nested Python Loops**: Instead of eight `np.roll` calls and one `np.where`, we make two loops over `i, j` (10^4 iterations) and two more loops over `di, dj` (9 checks each), for roughly 9x10^4 Python level operation per step. \n",
    "- **Manual edge-wrapping logic**: Branching (`if ni < 0 … elif …`) for each neighbour check, instead of the single fast shift that `np.roll` does in C. \n",
    "- **Per-cell rule application** The game of life rule is applied with Python `if/else` instead of the single vectorised Boolean mask. \n",
    "- **Rebuilding a new NumPy array element-by-element**: writing into `new_grid[i, j]` in Python is orders of magnitude slower than one-shot `np.where`. \n",
    "\n",
    "Together, these overheads make this version run very slow, particularly as `N` begins to increase, and would not leverage any low-level C loops or GPU acceleration. \n",
    "\n",
    "## CPU-Vectorised Implementation \n",
    "\n",
    "```python\n",
    "def life_step_numpy(grid: np.ndarray) -> np.ndarray:\n",
    "    neighbours = (\n",
    "        np.roll(np.roll(grid, 1, axis=0), 1, axis=1) +\n",
    "        np.roll(np.roll(grid, 1, axis=0), -1, axis=1) +\n",
    "        np.roll(np.roll(grid, -1, axis=0), 1, axis=1) +\n",
    "        np.roll(np.roll(grid, -1, axis=0), -1, axis=1) +\n",
    "        np.roll(grid, 1, axis=0) +\n",
    "        np.roll(grid, -1, axis=0) +\n",
    "        np.roll(grid, 1, axis=1) +\n",
    "        np.roll(grid, -1, axis=1)\n",
    "    )\n",
    "    return np.where((neighbours == 3) | ((grid == 1) & (neighbours == 2)), 1, 0)\n",
    "\n",
    "\n",
    "def simulate_life_numpy(N: int, timesteps: int, p_alive: float = 0.2):\n",
    "    grid = np.random.choice([0, 1], size=(N, N), p=[1-p_alive, p_alive])\n",
    "    history = []\n",
    "    for _ in range(timesteps):\n",
    "        history.append(grid.copy())\n",
    "        grid = life_step_numpy(grid)\n",
    "    return history\n",
    "```\n",
    "\n",
    "### Explanation\n",
    "\n",
    "#### From Per-Cell Loops to Whole-Array Operations \n",
    "\n",
    "In the **naive** version, every one of the NxN cells in Python was traversed within two nested loops; then, for each cell, two more loops over the offsets `di` and `dj` counted its eight neighbours by computing. `(i + di) % N` and `(j + dj) % M` in pure Python. \n",
    "**Cost**: ~9·N² Python-level iterations per generation, including branching and modulo arithmetic.\n",
    "**Drawback** Thousands of interpreter calls and non-contiguous memory access. \n",
    "In the **NumPy** version, no Python loops over individual cells occur. Instead, eight calls to `np.roll` shift the entire grid array (up, down, left, right and on diagonals), automatically handling wrap-around in one C-level operation. Summing those eight arrays gives a full neighbour count in a single, optimised pass. \n",
    "\n",
    "#### Manual `if/else` vs Vectorised Mask \n",
    "\n",
    "In the **naive** implementation, after counting neighbours, each cell's fate is determined with a Python `if grid[i,j] == 1: ... else: ...` and assigned via `new[i,j] = ...`. \n",
    "In the **NumPy** implementation a single expression of `(neighbours == 3) | ((grid == 1) & (neighbours == 2))` produces an NxN Boolean mask of *cells alive next*. Converting that mask to integers with `np.where(mask, 1, 0)` builds the entire next-generation grid in one C-level operation, resulting in no per-element Python overhead. \n",
    "\n",
    "#### Automatic Wrap-Around vs Manual Modulo Logic\n",
    "\n",
    "In the **naive** version, every neighbour checks does: \n",
    "\n",
    "```python \n",
    "ni = (i + di) % N\n",
    "nj = (j + dj) % M\n",
    "```\n",
    "\n",
    "with Python-level branching and modulo arithmetic on each of the 9 checks per cell. The associated **cost** is thousands of modulo (`%`) operations and branch instructions per generation. \n",
    "\n",
    "In the **NumPy** version, a single call to \n",
    "\n",
    "```python\n",
    "np.roll(grid, shift, axis=)\n",
    "```\n",
    "\n",
    "automatically wraps the entire array in one C-level operation. The **benefit** is that all per-cell `%` operations and branching are eliminated, being replaced by a single optimised memory shift over the whole grid. \n",
    "\n",
    "## GPU-Accelerated Implementation \n",
    "\n",
    "```python\n",
    "def life_step_gpu(grid: cp.ndarray) -> cp.ndarray:\n",
    "    neighbours = (\n",
    "        cp.roll(cp.roll(grid, 1, axis=0), 1, axis=1) +\n",
    "        cp.roll(cp.roll(grid, 1, axis=0), -1, axis=1) +\n",
    "        cp.roll(cp.roll(grid, -1, axis=0), 1, axis=1) +\n",
    "        cp.roll(cp.roll(grid, -1, axis=0), -1, axis=1) +\n",
    "        cp.roll(grid, 1, axis=0) +\n",
    "        cp.roll(grid, -1, axis=0) +\n",
    "        cp.roll(grid, 1, axis=1) +\n",
    "        cp.roll(grid, -1, axis=1)\n",
    "    )\n",
    "    return cp.where((neighbours == 3) | ((grid == 1) & (neighbours == 2)), 1, 0)\n",
    "\n",
    "\n",
    "def simulate_life_cupy(N: int, timesteps: int, p_alive: float = 0.2):\n",
    "    grid_gpu = (cp.random.random((N, N)) < p_alive).astype(cp.int32)\n",
    "    history = []\n",
    "    for _ in range(timesteps):\n",
    "        history.append(cp.asnumpy(grid_gpu))\n",
    "        grid_gpu = life_step_gpu(grid_gpu)\n",
    "    return history\n",
    "\n",
    "```\n",
    "\n",
    "### CuPy vs NumPy: What's Changed.\n",
    "\n",
    "The power of **CuPy** lies in its near drop-in compatibility with **NumPy**: arrays live on the GPU, and computations run in parallel on the Device, yet the code looks almost identical. \n",
    "\n",
    "#### Imports \n",
    "\n",
    "The first change you will need to make is to use CuPy rather than NumPy. \n",
    "**NumPy**: \n",
    "```Python \n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "**CuPy**: \n",
    "```Python \n",
    "import cupy as cp\n",
    "```\n",
    "\n",
    "#### Random initialisation \n",
    "\n",
    "**NumPy**: \n",
    "```Python \n",
    "grid = np.random.choice([0,1], size=(N,N), p=[1-p, p])\n",
    "```\n",
    "\n",
    "**CuPy**: \n",
    "```Python \n",
    "grid_gpu = (cp.random.random((N,N)) < p_alive).astype(cp.int32)\n",
    "```\n",
    "\n",
    "#### Data Transfer\n",
    "\n",
    "**CuPy**: \n",
    "\n",
    "```Python \n",
    "cp.asnumpy(grid_gpu)  # bring a CuPy array back to NumPy\n",
    "```\n",
    "\n",
    "### Which to use?\n",
    "\n",
    "**Large grids (e.g. N ≥ 500) or many timesteps**: GPU's parallel throughput outweighs kernel-launch and transfer overhead.\n",
    "**Small grids (e.g. 10×10)**: GPU overhead may dominate, so you may want to stick with NumPy.\n",
    "\n",
    "### Why is this quicker?\n",
    "\n",
    "When a computation can be expressed as the same operation applied independently across many data elements, like counting neighbours on every cell of a large Game of Life grid, GPUs often deliver dramatic speedups compared to CPUs. This advantage stems from several architectural and compiler-related factors that we discussed earlier in the section on theory, including: \n",
    "\n",
    "- **Massive Data Parallelism**\n",
    "    - **CPU**: A few (4–16) powerful cores optimised for sequential tasks and complex control flow.\n",
    "    - **GPU**: Hundreds to thousands of simpler cores running in lock-step.\n",
    "    - **Result**: A Game of Life update, which is identical work on each of N² cells, can be dispatched as thousands of parallel GPU threads, sweeping through the grid in a single kernel launch instead of looping in software.\n",
    "- **Throughput-Oriented Design**\n",
    "    - **CPU cores** focus on single-thread performance (high clock speeds, deep pipelines, branch prediction).\n",
    "    - **GPU cores** sacrifice single-thread speed in favour of raw arithmetic throughput and memory bandwidth across many threads.\n",
    "    - **Result**: When you need to process millions of cell updates, the GPU's aggregate arithmetic and memory bandwidth far outstrips what a CPU can deliver.\n",
    "- **Specialised Memory Hierarchy**\n",
    "    - **CPU**: Large multi-level caches and direct access to system RAM.\n",
    "    - **GPU:** High-bandwidth device memory (VRAM), with its own caches and shared memory for thread blocks.\n",
    "    - **Result**: Once the grid is transferred to GPU memory, all subsequent neighbour-count rolls and mask evaluations occur on-device, benefiting from coalesced global reads and fast on-chip scratchpads.\n",
    "- **Compiled GPU Kernels vs. Interpreted Loops**\n",
    "    - **CPU code** that uses Python loops incurs per-iteration interpreter overhead. Even NumPy's C loops run on a single core.\n",
    "    - **GPU kernels** compiled ahead of time by NVCC or generated at runtime execute the same inner logic entirely in device code without returning to Python between elements.\n",
    "    - **Result**: You replace thousands of Python bytecode dispatches or even C-loop iterations with just a few kernel launches and a handful of device-resident function calls.\n",
    "\n",
    "**In summary,**, for problems like Conway's Game of Life, where the same simple computation is applied independently across a large array, GPUs excel by running thousands of data-parallel threads in hardware, backed by specialised memory systems and aggressive compiler optimisations. Offloading to the GPU transforms an O(N²) loop of Python or C iterations into just a handful of highly parallel kernel launches, yielding orders-of-magnitude speedups on sufficiently large grids.\n",
    "\n",
    "### How much quicker?\n",
    "\n",
    "Each implementation exhibits a different overall runtime, as you have probably noticed when running them from the command line. We can use the built-in UNIX command line tool `time` to measure the time that is taken to run the code. The `time` command is a simple profiler that measures how long a given program takes to run. It provides three primary metrics, including:\n",
    "\n",
    "- **real**: The \"wall-clock\" time elapsed from start to finish (i.e. actual elapsed time).\n",
    "- **user**: CPU time spent in user-mode (your programs own computations)\n",
    "- **sys**: CPU time spent in kernel mode (system calls on behalf of your program)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379cd58-8b99-494b-a276-c947c57f83f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "full-width"
    ]
   },
   "source": [
    "````{div} full-width\n",
    "#### Framework Comparison on Each Machine\n",
    "\n",
    "<div style=\"display:flex; flex-wrap: wrap; gap:1em; margin-bottom:2em;\">\n",
    "\n",
    "  <!-- A100 -->\n",
    "  <div style=\"flex:1 1 30%; text-align:center;\">\n",
    "    <img src=\"../../_static/intro_to_gpu_figures/perf_amd_epyc_7v12_64-core_processor_nv_a100.png\"\n",
    "         alt=\"AMD 64-Core + NV A100\" style=\"max-width:100%; height:auto;\"/>\n",
    "    <div style=\"text-align:center; margin:2em 0;\">\n",
    "      <h3>AMD 64-Core + NV A100</h3>\n",
    "      <p>\n",
    "        <strong>CuPy</strong> pays a ~2.7 s launch cost but then stays nearly flat up to 2.5 k cells, after which it grows to ~42.9 s at 40 k.  \n",
    "        <strong>NumPy</strong> starts faster on very small grids (∼2.1 s at 250) but surpasses CuPy by 500–1 k cells and balloons to ~239 s at 10 k.  \n",
    "        The <strong>naive</strong> triple loop is usable only below 250×250—beyond that you hit >130 s at 500 and ~560 s at 1 k.\n",
    "      </p>\n",
    "      <p>\n",
    "        <em>Takeaway:</em> On the A100, CuPy becomes the clear winner past ~600 cells per side. NumPy is fine for a few hundred but uncompetitive beyond 1 k, and pure Python loops become unusable quickly.\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- H100 -->\n",
    "  <div style=\"flex:1 1 30%; text-align:center;\">\n",
    "    <img src=\"../../_static/intro_to_gpu_figures/perf_amd_epyc_9v84_96-core_processor_nv_h100.png\"\n",
    "         alt=\"AMD 96-Core + NV H100\" style=\"max-width:100%; height:auto;\"/>\n",
    "    <div style=\"text-align:center; margin:2em 0;\">\n",
    "      <h3>AMD 96-Core + NV H100</h3>\n",
    "      <p>\n",
    "        CuPy’s overhead shrinks slightly (~2.5 s) and its growth to ~26.1 s at 40 k is gentler than on the A100.  \n",
    "        NumPy remains sub-3 s until 1 k but then rises to ~222 s at 10 k, faster than the 64-core host only for the very largest sizes.  \n",
    "        Naive loops on this 96-core machine still hit ~62 s at 500 and ~265 s at 1 k.\n",
    "      </p>\n",
    "      <p>\n",
    "        <em>Takeaway:</em> The H100 host’s extra cores give NumPy ~10–20% speed-up over the 64-core EPYC, but CuPy is still >8× faster than NumPy past 2 k, and >100× faster than naive loops at 1 k.\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- RTX 3070 -->\n",
    "  <div style=\"flex:1 1 30%; text-align:center;\">\n",
    "    <img src=\"../../_static/intro_to_gpu_figures/perf_amd_ryzen_9_5950x_16-core_processor_nv_rtx_3070.png\"\n",
    "         alt=\"AMD 16-Core + NV RTX 3070\" style=\"max-width:100%; height:auto;\"/>\n",
    "    <div style=\"text-align:center; margin:2em 0;\">\n",
    "      <h3>AMD 16-Core + NV RTX 3070</h3>\n",
    "      <p>\n",
    "        The midrange RTX 3070 shows ~3.9 s overhead up to 1 k, then climbs to ~14.2 s at 10 k—still well below NumPy’s ~331.9 s at 10 k on 16 cores.  \n",
    "        However, because it has fewer SMs, the plateau appears earlier (around 5 k).  \n",
    "        Naive loops cross ~70 s at 500 and ~290 s at 1 k, so even here Python loops are unusable.\n",
    "      </p>\n",
    "      <p>\n",
    "        <em>Takeaway:</em> On consumer-grade hardware, CuPy wins beyond ~400 cells per side; NumPy can handle a few thousand but then spirals into minutes, and naive loops are only for toy problems.\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Machine Comparison on Each Framework\n",
    "\n",
    "<div style=\"display:flex; flex-wrap: wrap; gap:1em; margin-bottom:2em;\">\n",
    "\n",
    "  <!-- CuPy -->\n",
    "  <div style=\"flex:1 1 30%; text-align:center;\">\n",
    "    <img src=\"../../_static/intro_to_gpu_figures/cupy_across_hardware.png\"\n",
    "         alt=\"CuPy Across Hardware\" style=\"max-width:100%; height:auto;\"/>\n",
    "    <div style=\"text-align:center; margin:2em 0;\">\n",
    "      <h3>CuPy Across Hardware</h3>\n",
    "      <p>\n",
    "        All three GPUs show a ~2.5–4 s startup cost.  \n",
    "        The H100 host is the fastest at scale (∼26 s @40 k), followed by the A100 (∼43 s) and the RTX 3070 (∼14 s @10 k).  \n",
    "        Their scaling is roughly quadratic in grid side length, but the higher-end cards pull away as problem size grows.\n",
    "      </p>\n",
    "      <p>\n",
    "        <em>Insight:</em> If your grid exceeds ~1 k per side, even a midrange 3070 will beat any CPU—just be mindful of that initial launch overhead.\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- NumPy -->\n",
    "  <div style=\"flex:1 1 30%; text-align:center;\">\n",
    "    <img src=\"../../_static/intro_to_gpu_figures/numpy_across_hardware.png\"\n",
    "         alt=\"NumPy Across Hardware\" style=\"max-width:100%; height:auto;\"/>\n",
    "    <div style=\"text-align:center; margin:2em 0;\">\n",
    "      <h3>NumPy Across Hardware</h3>\n",
    "      <p>\n",
    "        Vectorised CPU performance scales with core count: the 96-core H100 host does ~2.9 s @1 k and ~222 s @10 k,  \n",
    "        the 64-core EPYC hits ~3.9 s @1 k and ~239 s @10 k,  \n",
    "        and the 16-core Ryzen only ~5.2 s @1 k but then ~332 s @10 k.\n",
    "      </p>\n",
    "      <p>\n",
    "        <em>Insight:</em> Doubling cores cuts runtime roughly in half, but you never beat the GPU’s parallelism for large areas.\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- Naive -->\n",
    "  <div style=\"flex:1 1 30%; text-align:center;\">\n",
    "    <img src=\"../../_static/intro_to_gpu_figures/naive_across_hardware.png\"\n",
    "         alt=\"Naive Across Hardware\" style=\"max-width:100%; height:auto;\"/>\n",
    "    <div style=\"text-align:center; margin:2em 0;\">\n",
    "      <h3>Naive Across Hardware</h3>\n",
    "      <p>\n",
    "        Pure Python loops are orders of magnitude slower across the board:  \n",
    "        even on the H100 host the run times are ~62 s @500 and ~265 s @1 k.  \n",
    "        On the 3070 machine it’s ~70 s @500, and on the A100 host ~132 s @500.\n",
    "      </p>\n",
    "      <p>\n",
    "        <em>Insight:</em> Triple-nested loops simply don’t scale. They’re only viable for extremely small toy problems (<250×250).\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Inter-Machine-Framework Comparison\n",
    "\n",
    "<div style=\"text-align:center; margin:2em 0;\">\n",
    "  <img src=\"../../_static/intro_to_gpu_figures/all_methods_hardware.png\"\n",
    "       alt=\"All Methods &amp; Hardware\" style=\"max-width:100%; height:auto;\"/>\n",
    "\n",
    "  <div style=\"display:inline-block; text-align:left; max-width:600px; margin-top:1em;\">\n",
    "    <h3 style=\"text-align:center;\">All Methods &amp; Hardware</h3>\n",
    "    <p>\n",
    "      Across all three machines, <strong>CuPy</strong> becomes faster than <strong>NumPy</strong> at roughly 500–1 k grid size,  \n",
    "      while <strong>naive loops</strong> are unusable past ~250.  \n",
    "      GPU dispatch overhead (~3 s) means tiny grids still favor NumPy or CPU,  \n",
    "      but anything beyond a few thousand cells per side is best done with CuPy on a modern accelerator.\n",
    "    </p>\n",
    "  </div>\n",
    "</div>\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147f851-ff6c-4a77-bc4e-338bc6de3d01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercise: Generate and Visualise Game-of-Life Performance Data\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "1. **Run** a SLURM job to generate timing data for Conway’s Game of Life on your platform.  \n",
    "2. **Modify or extend** the provided plotting script to visualize that data.  \n",
    "3. **Interpret** and discuss the performance trends you observe.\n",
    "\n",
    "> **Note:** This is an open-ended assignment—feel free to experiment with new plot styles, additional metrics, or entirely custom analyses.\n",
    "\n",
    "#### Generate Timing Data\n",
    "- Open the `game_of_life.slurm` slurm script.\n",
    "- Edit the script to match your cluster’s configuration (e.g. partition, module loads).  \n",
    "- Submit the job:\n",
    "\n",
    "```bash\n",
    "sbatch game_of_life.slurm\n",
    "```\n",
    "\n",
    "After completion, you’ll find CSV files in data/ named like:\n",
    "\n",
    "```bash\n",
    "gol_timings_<MachineName>_<Implementation>_ts100.csv\n",
    "```\n",
    "\n",
    "#### Review and Adapt the Starter Code\n",
    "The file `content/game_of_life_create_plots.py` contains:\n",
    "- CSV loading logic (from `data/`)\n",
    "- Function for:\n",
    "    - Per-machine “Framework vs Grid Size” plots\n",
    "    - Per-framework “Machine Comparison” plots  \n",
    "    - Combined “All Methods & Hardware” overlay\n",
    "\n",
    "You may wish to use them as they are, or you could:\n",
    "- Modify these functions (styles, scales, annotations).\n",
    "- Rewrite your own plotting script or Jupyter notebook.\n",
    "\n",
    "#### Visualisations\n",
    "Visualisations you could create include: \n",
    "- **Framework Comparison on Each Machine**: One figure per machine (e.g. A100, H100, RTX 3070) showing NumPy, Naive, CuPy timings vs. grid size.\n",
    "- **Machine Comparison on Each Framework**: One figure per framework, overlaying the three machines.\n",
    "- **All Methods & Hardware**: A combined overlay with all nine curves in a single plot.\n",
    "- **Any other plot you can think of!**\n",
    "\n",
    "#### Potential Enhancements\n",
    "To extend the work you are done, you could:\n",
    "- Calculate Speedup ratios (e.g. CPU_time / GPU_time).\n",
    "- Efficiency metrics such as time per cell or memory throughput.\n",
    "- Annotations marking crossover points or “break-even” grid sizes.\n",
    "- Interactive or animated plots (e.g. showing performance evolution as grid size increases).\n",
    "\n",
    "\n",
    "### Finer Grained Timing Information\n",
    "Our next step is to quantify those differences by measuring exactly how long each stage takes (pure computation, data transfers, grid initialisation, etc.) and to pinpoint where the bulk of the time is spent. The following section will address these questions by introducing profiling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6747f-c236-4504-985e-7b4d233a54f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

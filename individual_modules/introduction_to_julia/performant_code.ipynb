{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2ba956-7792-42e6-9c59-f1a85151e826",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Performant Code \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand basic strategies for writing high-performance Julia code \n",
    "- Learn about type stability and why it's important for performance \n",
    "- Recognise the importance of using functions and avoiding global variables on performance\n",
    "- Appreciate the benefit of avoiding unnecessary allocations\n",
    "- Understand that arrays are in column-major order and implications for performance\n",
    "- Appreciate how to choose appropriate data structures for a task to improve performance \n",
    "- Measure running time and memory allocation of code and identify bottlenecks using simple tools \n",
    "\n",
    "One of Julia's major appeals is performance. You can often write code in Julia that is both high-level and also runs nearly as fast as lower-level languages. However, to fully unlock this performance, it's good to be aware of a few tips and practices. Within this episode, we are going to introduce some key concepts: type stability, avoiding allocations, using efficient approaches, and basic profiling/timing.\n",
    "\n",
    "## Overview of Performance Tuning Strategies\n",
    "\n",
    "- Performance tuning in Julia often comes down to writing code that is easy for the compiler to optimise, which includes: \n",
    "- Ensuring computations are type-stable: the types of variables don't change unpredictably. \n",
    "- Avoiding global variables in tight loops or computations: use functions to encapsulate logic. \n",
    "- Reducing memory allocations when possible, for example, by modifying data in place or using views for subarrays instead of making copies.\n",
    "- Respecting the column-major order of arrays.\n",
    "- Choose the right data structure, e.g. using arrays, tuples, and dictionaries appropriately. \n",
    "- Measuring and profiling to find where the time is actually being spent, so you can optimise where it matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3a445-21a0-4237-abb4-7c5a35a601f9",
   "metadata": {},
   "source": [
    "## Measuring performance\n",
    "\n",
    "When we talk about 'performance', it can be helpful to think about this along two dimensions:\n",
    "- The execution time of the code\n",
    "- How much memory it needs to allocate\n",
    "\n",
    "There are interactions between these: code that has to allocate a lot of memory will slower than code that performs the same computations but doesn't allocate as much memory.\n",
    "\n",
    "Note: because Julia performs JIT compilation, when we need to assess the execution time we usually want to ensure we don't include the compilation time.\n",
    "\n",
    "> **Memory allocations: the heap**\n",
    ">\n",
    "> When we talk about 'allocations' in Julia, we are referring to **allocations of 'heap' memory**. In general, there are two types of RAM memory available when running a Julia process: the **stack** and the **heap**. The stack is a region of memory that stores local variables and function call information. Accessing and managing the lifetime of variables whose data is stored on the stack is very quick because the stack is a simple ordered layout of data. But this requires that the size the object and its type are known at compile time (and, for technical reasons, that the size of the object is not too large). In contrast, the heap is a region of memory used for dynamic memory allocation e.g. for objects that could grow / shrink in size as the program runs, such as arrays, or whose type changes. The heap is more flexible, but **it's more expensive to allocate and manage memory on the heap**. To manage the deallocation of data on the heap, Julia has a garbage collector that works in the background, which further adds to the cost of using the heap. Using the heap is not 'bad' per se: it's often essential for all but the simplest programs! However, using the stack where possible will make code much more performant. Several of the tips below revolve around avoiding unnecessary heap allocations.\n",
    " \n",
    "Julia provides some simple macros to measure execution time and memory:\n",
    "- `@time expression` runs `expression` once, printing both execution time (including compilation on the first run) and memory allocated. To see the \"steady-state\" performance (without compile-time overhead), run it a second time. \n",
    "- `@benchmark expression` (from `BenchmarkTools.jl`) runs `expression` many times, automatically \"warming-up\" the function. It reports statistics (min, median, mean, allocations, etc), so you avoid compile-time bias and see true variability. \n",
    "- `@timed expression` returns a `Timing` object containing fields like `time` and `allocs` rather than printing them, so you can programmatically inspect or log those metrics. \n",
    "- `@allocated expression` returns just the number of bytes allocated by running `expression`.\n",
    "\n",
    "For these notes we'll stick to using the built-in `@time` macro. Because it will include any JIT compilation, we typically need to run it twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c88cc92-9dba-45f0-a463-3e4f3550b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_squares -- first call:\n",
      "  0.021500 seconds (103.41 k allocations: 6.013 MiB, 99.51% compilation time)\n",
      "sum_squares -- second call:\n",
      "  0.000090 seconds (4 allocations: 800.078 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33276.41922708816"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sum_squares(arr)\n",
    "    return sum(map(x -> x^2, arr))\n",
    "end\n",
    "\n",
    "arr = rand(100_000)\n",
    "\n",
    "# First time includes compiling `sum_squares` for Vector{Float64}\n",
    "println(\"sum_squares -- first call:\")\n",
    "@time sum_squares(arr)\n",
    "\n",
    "# Second time doen't include compilation because Julia uses cached\n",
    "# compiled version\n",
    "println(\"sum_squares -- second call:\")\n",
    "@time sum_squares(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392c7e7-b599-434c-aa6c-9f8088a358e0",
   "metadata": {},
   "source": [
    "## Write functions and avoid global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87896a1a-44b9-4ad4-9653-e5cfb5e0c74b",
   "metadata": {},
   "source": [
    "Julia compiles and optimises functions just-in-time (JIT) when you call them, but code that lives in the global scope, such as a top-level loop that uses global variables, cannot be optimised as effectively. This is because globals might change type or value at any moment. \n",
    "\n",
    "**Best Practice**: encapsulate all performance-critical work inside a function, then invoke those functions, passing all required variables in as arguments. By doing so, you ensure the compiler sees only local variables with known, concrete types. \n",
    "\n",
    "For instance, rather than writing at the top level: \n",
    "\n",
    "```julia \n",
    "# Global loop – avoids type instability but still limits optimisation\n",
    "numbers = rand(1000)\n",
    "total = 0.0\n",
    "for x in numbers\n",
    "    total += x\n",
    "end\n",
    "println(total)\n",
    "```\n",
    "\n",
    "You would instead want to define and call a function: \n",
    "\n",
    "```julia \n",
    "function sum_array(arr::Vector{FLoat64})\n",
    "    total = 0.0            # local Float64\n",
    "    for x in arr           # x is Float64\n",
    "        total += x\n",
    "    end\n",
    "    return total\n",
    "end\n",
    "\n",
    "numbers = rand(1000)\n",
    "total = sum_array(numbers)\n",
    "println(total)\n",
    "```\n",
    "\n",
    "Inside `sum_array`, both `total` and `x` have fixed, known types, allowing the compiler to produce highly optimised code. In the global version, even though `total` is initialised as a `Float64`, its status as a global variable prevents the same level of optimisation. \n",
    "\n",
    "You *can* annotate a globals type:\n",
    "\n",
    "```julia\n",
    "global_total::Float64 = 0.0\n",
    "```\n",
    "\n",
    "This forbids it from ever changing to another type, but this still won't unlock all the optimisations you get inside functions. This is discussed further in the [Julia documentation](https://docs.julialang.org/en/v1/manual/performance-tips/#Avoid-untyped-global-variables).\n",
    "\n",
    "For truly constant values, always declare them with `const` at the global level. \n",
    "\n",
    "```julia \n",
    "const PI = 3.14\n",
    "```\n",
    "\n",
    "This signals to the compiler that `PI` will never change, enabling further speedups. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df983f4a-f260-47ab-9c68-47436a9f664f",
   "metadata": {},
   "source": [
    "## Type stability\n",
    "\n",
    "A function is **type-stable** if the (concrete) type of its return value can be determined from the types of its inputs **at compile time** i.e. without having to run the function in an actual program.\n",
    "\n",
    "You can use the `@code_warntype` macro when calling a function to check how type-stable it is:\n",
    " \n",
    "```Julia \n",
    "@code_warntype your_function(args)\n",
    "```\n",
    "\n",
    "Any areas in the function body where Julia cannot infer the types at compile time will be highlighted in orange/yellow or red, depending on the severity of the type instability. Let's look at some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbd4b5-edd7-4373-92ab-1e562b84f5d7",
   "metadata": {},
   "source": [
    "### Type-stable\n",
    "\n",
    "The following is an example of a **type-stable** function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785c152b-d2b5-4138-91b3-38e69b02b972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "squash_neg (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function squash_neg(x)\n",
    "    if x < 0\n",
    "        return zero(x)  # return 0 of same type same as typeof(x)\n",
    "    else\n",
    "        return x  # return type same as typeof(x)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09859e7c-6498-424a-9a83-66a33634b576",
   "metadata": {},
   "source": [
    "To see that this is type-stable, the question we need to ask is: _\"Suppose we're given the type of `x`. Can we unambiguously determine the return type of the function as a concrete type, given this and the code in the function body?\"_ In this case the answer is yes, because down each `if` branch, the type is uniquely determined by the type of `x` (indeed, in this case it happens to be the same as `typeof(x)`).\n",
    "\n",
    "We can verify this using the `@code_warntype` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c69d82b-a86c-476e-9baf-93bc4b1bcb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for squash_neg(::Float64)\n",
      "  from squash_neg(\u001b[90mx\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m\u001b[4mIn[2]:1\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(Main.squash_neg)\u001b[39m\n",
      "  x\u001b[36m::Float64\u001b[39m\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = Main.:<\u001b[36m::Core.Const(<)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %2 = (%1)(x, 0)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      goto #3 if not %2\n",
      "\u001b[90m2 ─\u001b[39m %4 = Main.zero\u001b[36m::Core.Const(zero)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %5 = (%4)(x)\u001b[36m::Core.Const(0.0)\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %5\n",
      "\u001b[90m3 ─\u001b[39m %7 = x\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@code_warntype squash_neg(1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e14def-b6c1-4be4-bcf6-97d73d779c2f",
   "metadata": {},
   "source": [
    "The output from `@code_warntype` shows that the output will be a `Float64` for the given `Float64` argument; all the variable types are clearly inferred, and there are no concerning red or yellow types. Julia can compile optimised machine code with no dynamic checks, which is the ideal case for performance. \n",
    "\n",
    "> **Note**\n",
    ">\n",
    "> Notice how we don't need to specify the types of the arguments in the signature for a function to be type-stable. Remember that Julia infers the types of its arguments and then compiles a version of the function specific to those types: type-stability comes into play after that inference has taken place. **Type annotations in signatures mainly help with dispatch, readability, and documentation; they rarely affect raw speed except in rare corner cases**, as discussed within the [Julia documentation](https://docs.julialang.org/en/v1/manual/functions/#Argument-type-declarations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eaa685-1e96-4b31-8476-cd4a7ff4bcbe",
   "metadata": {},
   "source": [
    "### Mildly Type-Unstable Function\n",
    "\n",
    "Let's make a small tweak to `squash_neg` to give an example of a type-**unstable** function (taken from the [Julia docs on performant code](https://docs.julialang.org/en/v1/manual/performance-tips/#Write-%22type-stable%22-functions)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403e89cb-8cdd-44a6-9cdf-22d881582780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "squash_neg2 (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function squash_neg2(x)\n",
    "    if x < 0\n",
    "        return 0  # an Int\n",
    "    else\n",
    "        return x  # return type same as typeof(x)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73f016-aecb-4096-979d-e28169a44c79",
   "metadata": {},
   "source": [
    "We've replaced the call to `zero(x)` with a literal `0`. This has made the function type unstable:\n",
    "- Sometimes it returns an **Int**, sometimes **typeof(x)** (which could be `Int`, `Int32`, `Float64`,...) \n",
    "- The type returned depends on the value of `x`, not just its type.\n",
    "- Therefore the compiler **can't predict** the output type just from the input types. \n",
    "- This would force Julia to **insert expensive type checks** at runtime for code that relies on this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c838dd3-1734-4d35-b9cd-fdd7766397d5",
   "metadata": {},
   "source": [
    "We can see this in detail using `@code_warntype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e81d06c-898c-4970-9f8b-ff350e435f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for squash_neg2(::Float64)\n",
      "  from squash_neg2(\u001b[90mx\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m\u001b[4mIn[4]:1\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(Main.squash_neg2)\u001b[39m\n",
      "  x\u001b[36m::Float64\u001b[39m\n",
      "Body\u001b[33m\u001b[1m::Union{Float64, Int64}\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = (x < 0)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      goto #3 if not %1\n",
      "\u001b[90m2 ─\u001b[39m      return 0\n",
      "\u001b[90m3 ─\u001b[39m %4 = x\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@code_warntype squash_neg2(1.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd611a10-0887-4260-abc9-0cdd5d1329f8",
   "metadata": {},
   "source": [
    "Above, you can see the mildly type-unstable function `squash_neg2`. In the `@code_warntype squash_neg2(1.2)` output, the return slot is highlighted in yellow as `Body::Union{Float64, Int64}`, indicating Julia infers it will return either a `Float64` or a `Int64` given the argument `1.2`, but it can't determine exactly which. At runtime, Julia must handle both possibilities. However, this situation is not as bad as it could be since there is only a choice of two types; the Julia compiler may still be able to perform some optimisations to ameliorate this.\n",
    "\n",
    "### Severely Type-Unstable Function: `sum_positive`\n",
    "\n",
    "Let's now look at a function that exhibits more serious type-instability.\n",
    "\n",
    "**Note**: Unfortunately the text below may not feature the red highlighting in the web version of these notes. Try running the code in your own Julia REPL to see the output colour highlighting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f973fac-d67d-4f4c-a2ed-d6657fa92ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for sum_positive(::Vector{Real})\n",
      "  from sum_positive(\u001b[90marr\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m\u001b[4mIn[6]:2\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(Main.sum_positive)\u001b[39m\n",
      "  arr\u001b[36m::Vector{Real}\u001b[39m\n",
      "Body\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = Main.sum\u001b[36m::Core.Const(sum)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %2 = Base.broadcasted(Main.squash_neg, arr)\u001b[36m::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, typeof(squash_neg), Tuple{Vector{Real}}}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %3 = Base.materialize(%2)\u001b[91m\u001b[1m::AbstractVector{<:Real}\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %4 = (%1)(%3)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sum the positive elements of an array of real numbers\"\"\"\n",
    "function sum_positive(arr)\n",
    "    sum(squash_neg.(arr))  # using vectorised version of squash_neg\n",
    "end\n",
    "\n",
    "arr = Real[1, -2.1, π]\n",
    "@code_warntype sum_positive(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a28fb-774d-4700-91b7-9e4f9d7e0222",
   "metadata": {},
   "source": [
    "The crucial line in the output is the following:\n",
    "```\n",
    "Body::Any\n",
    "```\n",
    "\n",
    "`Body::Any` is highlighted in **red**, indicating Julia could only infer that the return value is of type `Any`. As the input vector `arr` is a `Vector{Real}`, Julia has no way to know at compile time exactly what (concrete) type each `x` in `arr` will be. As a result, dynamic type-checking is required for each `x`, and the returned value is **boxed** as `Any`, resulting in heap allocations and the need for garbage collection. Boxing values means they are stored in the heap with additional type information rather than on the stack.\n",
    "\n",
    "#### Is it always that bad?\n",
    "\n",
    "What if we instead provide an array with concrete element type, such as `arr = [1, -2.1, π]` (a `Vector{Float64}`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdfa904f-a9cd-4d08-8b21-79c240ffa047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for sum_positive(::Vector{Float64})\n",
      "  from sum_positive(\u001b[90marr\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m\u001b[4mIn[6]:2\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(Main.sum_positive)\u001b[39m\n",
      "  arr\u001b[36m::Vector{Float64}\u001b[39m\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = Main.sum\u001b[36m::Core.Const(sum)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %2 = Base.broadcasted(Main.squash_neg, arr)\u001b[36m::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{1}, Nothing, typeof(squash_neg), Tuple{Vector{Float64}}}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %3 = Base.materialize(%2)\u001b[36m::Vector{Float64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %4 = (%1)(%3)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr = [1, -2.1, π]\n",
    "@code_warntype sum_positive(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fda506-563a-4f6a-bde1-5ef580aabcde",
   "metadata": {},
   "source": [
    "We can see that now the return type has been inferred to be `Float64` at compile time.\n",
    "\n",
    "Here, `sum_positive` is still technically *type‐unstable* in the general sense, because its return type depends entirely on what you pass in. However, in practice, that doesn’t always translate to slow code. The line\n",
    "\n",
    "```\n",
    "Body::Float64\n",
    "```\n",
    "\n",
    "shows that, for a `Vector{Float64}`, the result must be `Float64`, so it emits specialised, fully‐typed code.\n",
    "\n",
    "The takeaway is that, in this case, the element type of the actual argument matters just as much as your function. A function like `sum_positive` can be generally unstable, yet still perform optimally whenever you feed it collection with **concrete‐typed** elements (e.g. `Vector{Int64}` vs `Vector{Real}`).\n",
    "\n",
    "## Avoid containers with abstract elements\n",
    "\n",
    "In the example above, we supplied `sum_positive` with a `Vector{Real}`, i.e. an array where the element type can only be guaranteed to be the abstract `Real` type. Using abstract‐typed containers (e.g. `Vector{Any}`) forces Julia to fall back to run-time type checking and boxing. Keeping your collection parameterised over concrete element types is a crucial performance tip in Julia. So, for example, prefer to work with elements types `Float64`, `Int`, `Float32`, etc.\n",
    "\n",
    "The following code shows how far more allocations are required to compute `sum_positive` on a `Vector{Real}` compared to `Vector{Float64}`, due to the boxing required to work with `Real`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ba67820-d1a2-4b51-8093-3fe57d66af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.073071 seconds (4 allocations: 7.656 MiB, 98.86% gc time)\n",
      "  0.010718 seconds (1.00 M allocations: 22.915 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Vector of Float64\n",
    "arr = randn(1_000_000)\n",
    "\n",
    "# Same values but considered as a Vector of Real\n",
    "arr2 = Vector{Real}(undef, length(arr))\n",
    "arr2 .= arr\n",
    "\n",
    "# Run to compile\n",
    "sum_positive(arr); sum_positive(arr2);\n",
    "\n",
    "@time sum_positive(arr);\n",
    "@time sum_positive(arr2);  # more allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183789e3-7f87-4b91-9344-ca6f90cbf5fc",
   "metadata": {},
   "source": [
    "## Work with arrays in a column major way\n",
    "\n",
    "In Julia, arrays are stored in column-major order. This means that elements of a column (i.e. the first axis) are stored in contiguous memory locations. This has important performance implications when iterating through arrays.\n",
    "\n",
    "When you loop through an array, accessing elements in the order they are stored in memory can significantly improve performance due to better cache utilization. In column-major order, this means making sure we iterate through the first index more frequently than the second index, (which in turn should be more frequent than the third index, etc.). This is achieved by iterating through the first index in the inner-most loop, followed by the second index in the next loop up, etc. \n",
    "\n",
    "Let's look at an example of summing over the elements of a matrix to illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0726804-0282-491e-9ed0-3cb9d1880de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.177636 seconds (1 allocation: 16 bytes)\n",
      "  0.206866 seconds (1 allocation: 16 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Efficient: respects column-order\n",
    "# inner-most loop runs over first axis\n",
    "function sum_column_order(mat)\n",
    "   sum = 0 \n",
    "    for j in axes(mat, 2)\n",
    "        for i in axes(mat, 1)\n",
    "            sum += mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return sum\n",
    "end\n",
    "\n",
    "# Inefficient: uses row-order instead\n",
    "# inner-most loop runs over second axis\n",
    "function sum_row_order(mat)\n",
    "   sum = 0 \n",
    "    for i in axes(mat, 1)\n",
    "        for j in axes(mat, 2)\n",
    "            sum += mat[i, j]\n",
    "        end\n",
    "    end\n",
    "    return sum\n",
    "end\n",
    "\n",
    "\n",
    "# Run to compile\n",
    "sum_column_order(rand(2, 2)); sum_row_order(rand(2, 2));\n",
    "\n",
    "mat = rand(10_000, 10_000)\n",
    "@time sum_column_order(mat);\n",
    "@time sum_row_order(mat);  # slower!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec715e11-eb61-437d-a47c-a57456d2bd0c",
   "metadata": {},
   "source": [
    "## Avoid unnecessary allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b04353-011b-4801-99da-b7ba3cb3d03a",
   "metadata": {},
   "source": [
    "Common sources of excessive allocation include type-stability issues (discussed above), which force Julia to box values on the heap, and **creating many small temporary arrays**, for example via repeated slicing or non-in-place broadcast, as discussed in the [Julia documentation](https://docs.julialang.org/en/v1/manual/performance-tips/#Measure-performance-with-%5B@time%5D(@ref)-and-pay-attention-to-memory-allocation). \n",
    "\n",
    "Here are some strategies to cut down heap usage. Recall that we can use `@time` or `BenchmarkTools.@btime` and watch the \"allocations\" count.\n",
    "\n",
    "### Pre-allocate and reuse arrays\n",
    "\n",
    "Instead of building a new array each iteration, or repeatedly extending an array, instead pre-allocate a single array of the correct size and populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78dc03f6-f798-4310-be21-aabc934922b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.007722 seconds (1.00 M allocations: 32.812 MiB)\n",
      "  0.000686 seconds (2 allocations: 7.656 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Bad: extends array inside the loop\n",
    "function squares(arr)\n",
    "    results = []\n",
    "    for x in arr\n",
    "        push!(results, x^2)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Good: allocate once, then fill in place\n",
    "function squares2(arr)\n",
    "    results = similar(arr)\n",
    "    for (i, x) in enumerate(arr)\n",
    "        results[i] = x^2\n",
    "    end\n",
    "end\n",
    "\n",
    "arr = rand(1_000_000)\n",
    "\n",
    "# Run to compile\n",
    "squares(arr); squares2(arr);\n",
    "\n",
    "@time squares(arr)\n",
    "@time squares2(arr)  # fewer allocations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a4f0b-0127-4792-ac62-0d34eea74c51",
   "metadata": {},
   "source": [
    "### Use views for subarrays\n",
    "\n",
    "**Slicing an array creates a new copy of the data**. This is often not required, so instead you can use the `view` function to create a lightweight window into an array without copying its data, thus avoiding a fresh allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe99316-ced5-4996-a637-408a5270e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.016086 seconds (4 allocations: 38.156 MiB, 23.95% gc time)\n",
      "  0.003487 seconds (1 allocation: 16 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Bad: sum applied to a slice, which involves allocation\n",
    "function sum_at_even_indices(arr)\n",
    "    n = length(arr)\n",
    "    even_indices = 2:2:n\n",
    "    sum(arr[even_indices])  # slicing copies\n",
    "end\n",
    "\n",
    "# Good: sum applied to a view -- no allocation\n",
    "function sum_at_even_indices2(arr)\n",
    "    n = length(arr)\n",
    "    even_indices = 2:2:n\n",
    "    sum(view(arr, even_indices))  # view doesn't copy\n",
    "end\n",
    "\n",
    "# Run to compile\n",
    "sum_at_even_indices([1., 2.]); sum_at_even_indices2([1., 2.]);\n",
    "\n",
    "arr = rand(10_000_000)\n",
    "@time sum_at_even_indices(arr);\n",
    "@time sum_at_even_indices2(arr);  # fewer allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393373bb-01ea-4221-bfa3-9ab180f4e1ef",
   "metadata": {},
   "source": [
    "### Favour in-place operations\n",
    "\n",
    "Modifying objects in-place avoids (or at least reduces) needing to allocated new memory. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c992284a-3fe0-43a6-87cc-6e0e317f0e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.113018 seconds (9 allocations: 152.602 MiB, 12.56% gc time)\n",
      "  0.088945 seconds (6 allocations: 76.305 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Run to compile\n",
    "sort!([2.0, 1.0]); sort([2.0, 1.0])\n",
    "\n",
    "arr = rand(10_000_000)\n",
    "@time sorted = sort(arr);  # returns new array\n",
    "@time sort!(arr);    # rearranges in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46d38a-fb2d-4037-b30c-220f50b55aa3",
   "metadata": {},
   "source": [
    "### Fuse vectorised (broadcast) operations\n",
    "\n",
    "Recall that we can vectorise (i.e. apply element-wise) any function using the 'dot' notation. When repeated functions need to be vectorised in a chain, then we can 'fuse' these together. This saves allocating temporary, intermediary arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c815ae6b-b302-4eb7-a4d3-924f5b32b306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.009816 seconds (15 allocations: 38.282 MiB)\n",
      "  0.006306 seconds (3 allocations: 7.656 MiB)\n"
     ]
    }
   ],
   "source": [
    "# Bad: intermediary variables involve allocations\n",
    "function sin_of_cubic(x::Vector{Float64})\n",
    "    cubed = x.^3\n",
    "    squared = x.^2\n",
    "    sin_cubed = sin.(cubed)\n",
    "    sin_squared = sin.(squared)\n",
    "    return sin_cubed .+ sin_squared\n",
    "end\n",
    "\n",
    "# Good: fusing multiple 'dot' calls avoids allocations\n",
    "function sin_of_cubic2(x::Vector{Float64})\n",
    "    return sin.(x.^3) .+ sin.(x.^2)\n",
    "end\n",
    "\n",
    "# Run to compile\n",
    "sin_of_cubic([1.0]); sin_of_cubic2([1.0])\n",
    "\n",
    "x = rand(1_000_000)\n",
    "@time sin_of_cubic(x);\n",
    "@time sin_of_cubic2(x);  # fused -> fewer allocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc346f-b5b4-4031-9895-d628fd9ab834",
   "metadata": {},
   "source": [
    "## Use appropriate data structures\n",
    "\n",
    "Some key considerations when determining which data structure to use include: \n",
    "- If you need random access to elements by index and the collection will grow/shrink, you require a Vector (`Array`). \n",
    "- If you need to look up values by keys, use a `Dict` instead of searching through an array each time. \n",
    "- If you have a fixed small set of values of heterogenous types, a `Tuple` can be helpful. They are immutable, and their types are part of their identity, making them very efficient for specific uses, like returning multiple values from a function. \n",
    "- If you need stack or queue behaviour, you can still use arrays (with `push!` or `pop!` for the stack and `push!` and `popfirst!` for the queue. \n",
    "- If you have binary data or bits, consider `BitVector` for large boolean arrays that are memory efficient. \n",
    "- For mathematical operations, using native numeric types (`Int`, `Float64`) is faster than arbitrary precisions or rational types, so only use `BigInt`, `BigFloat` and `Rational` when needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef9a34-9ebf-4dea-8a7e-8b244056e049",
   "metadata": {},
   "source": [
    "## Clever algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c737482-6c55-4847-9701-d65ad01bda18",
   "metadata": {},
   "source": [
    "Often, the most considerable speedups come not from micro-optimising memory, but from choosing better algorithms or mathematical shortcuts. For example, instead of summing the first *N* integers in a loop: \n",
    "\n",
    "```julia \n",
    "function sum1(N)\n",
    "    total = 0\n",
    "    for i in 1:N\n",
    "        total += i\n",
    "    end\n",
    "    return total\n",
    "end\n",
    "```\n",
    "\n",
    "You can use the closed-form formula: \n",
    "\n",
    "\n",
    "```julia \n",
    "sum2(N) = N * (N + 1) ÷ 2\n",
    "```\n",
    "\n",
    "This runs in constant time rather than being based on the size of the input, and allocates no extra memory. Whenever possible, look for algorithmic improvements or analytic formulas before resorting to low-level optimisations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b286e5-fdc4-41d5-bbfd-b46f2abe5107",
   "metadata": {},
   "source": [
    "## Profiling for bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09a23a-401c-49e2-a559-717af4787e64",
   "metadata": {},
   "source": [
    "If you have a complex program and you want to see where it spends time, you can use Julia's standard library module `Profile`: \n",
    "\n",
    "```Julia \n",
    "using Profile\n",
    "@profile my_long_running_function()\n",
    "```\n",
    "\n",
    "Then use `Profile.print()` or a third party package to analyse the results. Profiling tells you which functions or lines are taking the most time. See https://docs.julialang.org/en/v1/manual/profile/ for more details on profiling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09fd1c6-f11e-4b9a-9b35-ee4705a36f3b",
   "metadata": {},
   "source": [
    "## Credits / further information\n",
    "\n",
    "The following guides were used for putting this episode together. They provide excellent reading if you want to dig further into performance optimisations and what's going on under the hood in terms of using your computer's hardware efficiently.\n",
    "\n",
    "- [Julia docs guide on performant code](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "- [Lecture from MIT course by Chris Rackauckas on optimising (serial) code ](https://mitmath.github.io/18337/lecture2/optimizing)\n",
    "- [Notebook by Jakob Nissen on _What scientists must know about hardware to write fast code_](https://viralinstruction.com/posts/hardware/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab27e0-1f3f-428d-89ac-5ebe345eca9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise: Analysing the Performance of Code \n",
    "\n",
    "Given the three functions below, use what we've discussed so far about type stability, allocations, and performance to understand **why they perform differently**.\n",
    "\n",
    "```Julia \n",
    "function method_1(N)\n",
    "    arr = Int[]  \n",
    "    for i in 1:N\n",
    "        push!(arr, i)      \n",
    "    end\n",
    "    return sum(arr)        \n",
    "end\n",
    "\n",
    "\n",
    "function method_2(N)\n",
    "    arr = collect(1:N)  # collect the range 1:N into a Vector{Int}\n",
    "    return sum(arr)\n",
    "end\n",
    "\n",
    "\n",
    "function method_3(N)\n",
    "    return N*(N+1)÷2\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce9eb5-592d-41b1-ad9c-83110249a756",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# End of Section Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66284760-424f-44d7-85c3-342bffb1c98a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".quiz-question {\n",
       "    background-color: #392061;\n",
       "    color: white;\n",
       "    padding: 12px;\n",
       "    border-radius: 10px;\n",
       "    font-weight: bold;\n",
       "    font-size: 1.2em;\n",
       "    margin-bottom: 10px;\n",
       "}\n",
       "\n",
       ".quiz-form {\n",
       "    margin-bottom: 20px;\n",
       "}\n",
       "\n",
       ".quiz-answer {\n",
       "    display: block;\n",
       "    background-color: #f2f2f2;\n",
       "    border: none;\n",
       "    border-radius: 10px;\n",
       "    padding: 10px;\n",
       "    margin: 5px 0;\n",
       "    font-size: 1em;\n",
       "    cursor: pointer;\n",
       "    text-align: left;\n",
       "    transition: background-color 0.3s;\n",
       "    width: 100%;\n",
       "}\n",
       "\n",
       ".quiz-answer:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".correct {\n",
       "    background-color: #4CAF50 !important;\n",
       "    color: white !important;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       ".incorrect {\n",
       "    background-color: #D32F2F !important;\n",
       "    color: white !important;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       ".feedback {\n",
       "    margin-top: 10px;\n",
       "    font-weight: bold;\n",
       "    font-size: 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "function handleAnswer(qid, aid, feedback, isCorrect) {\n",
       "    let buttons = document.querySelectorAll(\".answer-\" + qid);\n",
       "    buttons.forEach(btn => {\n",
       "        btn.classList.remove('correct', 'incorrect');\n",
       "    });\n",
       "\n",
       "    let selected = document.getElementById(aid);\n",
       "    selected.classList.add(isCorrect ? 'correct' : 'incorrect');\n",
       "\n",
       "    let feedbackBox = document.getElementById('feedback_' + qid);\n",
       "    feedbackBox.innerHTML = feedback;\n",
       "    feedbackBox.style.color = isCorrect ? 'green' : 'red';\n",
       "}\n",
       "</script>\n",
       "<div class=\"quiz-question\">Which function is recommended for pre-allocating an array of zeros in Julia for better performance?</div><form class=\"quiz-form\"><button type=\"button\" class=\"quiz-answer answer-1\" id=\"q1_a1\"\n",
       "    onclick=\"handleAnswer('1', 'q1_a1', 'Incorrect', false)\">\n",
       "    array_zeros()\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-1\" id=\"q1_a2\"\n",
       "    onclick=\"handleAnswer('1', 'q1_a2', 'Correct', true)\">\n",
       "    zeros()\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-1\" id=\"q1_a3\"\n",
       "    onclick=\"handleAnswer('1', 'q1_a3', 'Incorrect', false)\">\n",
       "    preallocate()\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-1\" id=\"q1_a4\"\n",
       "    onclick=\"handleAnswer('1', 'q1_a4', 'Incorrect', false)\">\n",
       "    fill(0, dims...)\n",
       "</button>\n",
       "<div class=\"feedback\" id=\"feedback_1\"></div>\n",
       "<button type=\"submit\" style=\"position:absolute; left:-9999px; width:1px; height:1px; overflow:hidden;\">\n",
       "    Submit\n",
       "</button>\n",
       "</form><hr>\n",
       "<div class=\"quiz-question\">In Julia, why should you avoid growing arrays inside a loop without pre-allocation?</div><form class=\"quiz-form\"><button type=\"button\" class=\"quiz-answer answer-2\" id=\"q2_a1\"\n",
       "    onclick=\"handleAnswer('2', 'q2_a1', 'Incorrect', false)\">\n",
       "    It uses too much memory instantly\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-2\" id=\"q2_a2\"\n",
       "    onclick=\"handleAnswer('2', 'q2_a2', 'Incorrect', false)\">\n",
       "    It causes syntax errors\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-2\" id=\"q2_a3\"\n",
       "    onclick=\"handleAnswer('2', 'q2_a3', 'Correct', true)\">\n",
       "    It results in repeated memory reallocation, which slows down the code\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-2\" id=\"q2_a4\"\n",
       "    onclick=\"handleAnswer('2', 'q2_a4', 'Incorrect', false)\">\n",
       "    It leads to incorrect computation results\n",
       "</button>\n",
       "<div class=\"feedback\" id=\"feedback_2\"></div>\n",
       "<button type=\"submit\" style=\"position:absolute; left:-9999px; width:1px; height:1px; overflow:hidden;\">\n",
       "    Submit\n",
       "</button>\n",
       "</form><hr>\n",
       "<div class=\"quiz-question\">What is a general tip for writing more performant Julia code when using loops?</div><form class=\"quiz-form\"><button type=\"button\" class=\"quiz-answer answer-3\" id=\"q3_a1\"\n",
       "    onclick=\"handleAnswer('3', 'q3_a1', 'Incorrect', false)\">\n",
       "    Always use global variables inside loops\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-3\" id=\"q3_a2\"\n",
       "    onclick=\"handleAnswer('3', 'q3_a2', 'Correct', true)\">\n",
       "    Minimise memory allocation inside loops\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-3\" id=\"q3_a3\"\n",
       "    onclick=\"handleAnswer('3', 'q3_a3', 'Incorrect', false)\">\n",
       "    Nest as many loops as possible\n",
       "</button>\n",
       "<button type=\"button\" class=\"quiz-answer answer-3\" id=\"q3_a4\"\n",
       "    onclick=\"handleAnswer('3', 'q3_a4', 'Incorrect', false)\">\n",
       "    Prefer string operations over numerical operations\n",
       "</button>\n",
       "<div class=\"feedback\" id=\"feedback_3\"></div>\n",
       "<button type=\"submit\" style=\"position:absolute; left:-9999px; width:1px; height:1px; overflow:hidden;\">\n",
       "    Submit\n",
       "</button>\n",
       "</form><hr>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../../julia_functions/quiz_renderer.jl\")\n",
    "show_quiz_from_json(\"questions/summary_performant_code.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7f0b8-70aa-4629-825c-962cabe887d2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

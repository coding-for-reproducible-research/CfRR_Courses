{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "suppressPackageStartupMessages({\n",
    "  suppressMessages({\n",
    "    library(data.table)\n",
    "    library(dplyr)\n",
    "    library(learnr)\n",
    "    library(microbenchmark)\n",
    "    library(parallel)\n",
    "    library(parallelly)\n",
    "    library(profvis)\n",
    "    library(Rcpp)\n",
    "    library(styler)\n",
    "  })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelisation Using the `parallel` Package\n",
    "The following section is based off of [these notes](https://dept.stat.lsa.umich.edu/~jerrick/courses/stat506_f24/16-parallel-processing.html) written by Josh Errickson at the University of Michigan. Additional information can be found in the [documentation](https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf) for the parallel package.\n",
    "\n",
    "## Overview\n",
    "Suppose you have found yourself in one of the following situations:\n",
    "\n",
    "1.    You have a function $f$ that you need to run **many** times for different input values. \n",
    "2.    You have a large set of functions $f_1, \\, \\dots\\, , f_n$, $n>>1$, that you need to run, each for potentially many different input values.\n",
    "\n",
    "If you're like me, you'd probably prefer to get straight to analyzing the data produced by the functions as opposed to waiting around all day for them to finish running. This is where parallelization can help you.\n",
    "\n",
    "We consider the case here where each function evaluation is completely independent of the others. In case 1 above, this is trivial because you're just running the same function for many different input combinations. In the second scenario, this means that the functions are completely unrelated e.g. the output of one function is never used as the input to another.\n",
    "\n",
    "A core on your computer can be thought of as an individual unit that can execute tasks. The vast majority of modern computers have multiple cores and parallelising your code involves sending independent jobs to different cores on your computer. In `R` one way of doing this is by using a concept called **forking**. \n",
    "\n",
    "## Forking (Will not work on Windows)\n",
    "Forking in `R` can be achieved using the `parallel` package, but first you should check that forking is actually supported within the environment in which you are developing your `R` code. Do do this, you can use the `supportsMulticore()` function from the `parallelly` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "supportsMulticore() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RStudio, depending on the version, the above may return `FALSE`, meaning forking is **NOT** supported, so you **may** not see any performance enhancements by using forking when running scripts in RStudio. Note I said **may**; as we will see below, using functions from the `parallel` package in Rstudio appear to behave well. However it is highly discouraged as the behaviour can be unexpected.\n",
    "\n",
    "The advised way to use forking is to run `R` scripts using your terminal. Suppose you have a script called `my-script.R`. There are two ways to use your terminal to run `my-script.R`:\n",
    "\n",
    "1.    Initiate an R session directly in the terminal, in the same directory as `my-script.R`, by typing `R`. Within the session type `source(\"my-script.R\")`\n",
    "2.    Execute `my-script.R` directly using the `Rscript` command in your terminal, i.e. by typing `Rscript my-script.R`\n",
    "\n",
    "## Exercise\n",
    "Implement the above procedure both inside and outside of RStudio, what are the results on your OS?\n",
    "\n",
    "## Forking - `mclapply()`\n",
    "First, let's detect the number of cores available on our machine using `detectCores()` from the `parallel` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "num_cores <- detectCores()\n",
    "num_cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, this returns 12, though on yours it may return something different. The output of `detectCores()` provides a useful guide on deciding how many cores to parallelise across, which can be specified in the `mclapply()` via the `mc.cores` argument. There are several important points here:\n",
    "\n",
    "1.    A value of two or greater for `mc.cores` is necessary for parallelisation. Setting `mc.cores = 1` will disable parallelisation. \n",
    "2.    It is not the case that choosing $n$ cores will result in a speed up of a factor of $n$. \n",
    "3.    Setting `mc.cores` higher than the number of available cores can actually slow down your code due to the overhead it creates. Using `detectCores()/2` is a useful starting point, and you can experiment from there.\n",
    "\n",
    "Now let's see `mclapply()` in action. Consider the following toy function, similar to the, which is used simply to represent an expensive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "slow_function <- function(n) {\n",
    "  Sys.sleep(1)\n",
    "  return(mean(rnorm(1000)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run using the regular `lapply()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "is <- 1:24\n",
    "t1 <- system.time(lapply(is, slow_function))[\"elapsed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run using parallelisation with `mclapply()` with four cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "t4 <- system.time(mclapply(is, slow_function, mc.cores = 4))[\"elapsed\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run using parallelisation with `mclapply()` with eight cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "t8 <- system.time(mclapply(is, slow_function, mc.cores = 8))[\"elapsed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run using parallelisation with `mclapply()` with twelve cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "t12 <- system.time(mclapply(is, slow_function, mc.cores = 12))[\"elapsed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "ts <- c(t1, t4, t8, t12)\n",
    "cs <- c(1, 4, 8, 12)\n",
    "plot(cs, ts, type = 'b', bty='l', xlab = \"mc.cores\", ylab = \"Time (s)\", pch = 20, main = \"Time vs Number of Cores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "Try to use `mclapply()` on one of your own functions, both inside and outside of Rstudio. Do you notice any difference in speed? Note `mclapply()` only parallelises over one argument. For multivariate parallelisation, see `mcmapply()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

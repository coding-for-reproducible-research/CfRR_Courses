{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "* Perform linear regression using scikit-learn \n",
    "* Explain the concepts of training a linear model that generalises well from few observations\n",
    "* Explain what training is, in terms of updating coefficients in linear models \n",
    "* Understand that these concepts hold in more dimensions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "We will start with the most familiar linear regression, a straight-line fit to data.\n",
    "A straight-line fit is a model of the form:\n",
    "\n",
    "$$\n",
    "y = mx + c\n",
    "$$\n",
    "\n",
    "where $m$ is commonly known as the *slope*, and $c$ is commonly known as the *intercept*. $y$ is the value that were trying to predict.\n",
    "\n",
    "Consider the following data, which is scattered about a line with a slope of 2 and an intercept of â€“5 (see the following figure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "\n",
    "x = 3 * rng.rand(50)\n",
    "y = 2 * x - 5 + rng.randn(50)\n",
    "\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a linear model of this data, or a line of best fit, that can help us make predictions. This process is as follows:\n",
    "\n",
    "* Select a model that we think will represent the data well (i.e. here, a linear model)\n",
    "* Find the straight line that minimises a distance to each point (i.e. train a model)\n",
    "* Use this line of best fit to create new predictions, which we can then plot\n",
    "\n",
    "Finding the line of best fit here means setting the model parameters (i.e. $m$ and $c$) such that they best fit the training data. We can fit a linear model to this data very easily using the `scikit-learn` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Reshape x to 2D vector X: (50,1)\n",
    "X = x.reshape(-1, 1)\n",
    "\n",
    "# Create and fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our slope should be close to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Slope: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intercept should be close to -5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make predictions for a single new data point as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 1.5\n",
    "X_new = [[1.5]]\n",
    "\n",
    "y_pred_new = model.predict(X_new)[0]\n",
    "\n",
    "print(f\"New x value: {x_new}, predicted y value: {y_pred_new:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this new data point on our graph to see if it roughly fits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.scatter(x_new, y_pred_new, marker=\"x\", s=200, label=\"New y prediction\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully created a single new prediction from a new $x$ value. \n",
    "\n",
    "To create a line of best fit, what do we need? We need to use the model to make many predictions. We can create $y_{pred}$, predicted $y$ values from our model, given a vector of input data. Conveniently, we can use our existing $x$ values collectively, as a vector $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, label=\"Predictions\", c=\"orange\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line plot obfuscates what is going on here. Let's make a scatter plot of our predictions instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, s=10)\n",
    "plt.scatter(x, y_pred, label=\"Predictions\", s=10)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does \"best\" mean?\n",
    "\n",
    "When we trained our linear model, we needed to define a cost function. We will talk a bit more about these later, but for a linear model, we commonly use the Root Mean Squared Error ($RMSE$), or just the Mean Squared Error, or $MSE$:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $y_i$ = Actual value of the $i^{th}$ data point\n",
    "- $\\hat{y}_i$ = Predicted value from the regression line, a member of `y_pred`\n",
    "- $n$ = Total number of data points\n",
    "\n",
    "We can visualise this by plotting a line between every data point, and every prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, s=10)\n",
    "plt.scatter(x, y_pred, label=\"Predictions\", s=10)\n",
    "\n",
    "for i, x_i in enumerate(x):\n",
    "    plt.plot([x_i, x_i], [y[i], y_pred[i]], color='black', linestyle='dashed')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont need to compute $MSE$ manually. We can import this from `scikit-learn`. We will discuss this in more detail later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "print(f\"MSE value: {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does training mean?\n",
    "\n",
    "Now that we have a measure of how well our model fits the data (the $MSE$), how does `scikit-learn` actually set the model coefficients such that the $MSE$ is minimised?\n",
    "\n",
    "In general, when we use the word training, an iterative approach is implied. For example, some machine learning algorithms use gradient descent to tweak the parameters (or coefficients) such that the cost function is minimised. \n",
    "\n",
    "However, linear regression is special in that the model has a closed-form/exact solution. This is provided below for completeness, but is a bit heavy on the mathematics to dig into in this course.\n",
    "\n",
    "**Note**: Technically, it uses singular value decomposition. Read more [here](https://scikit-learn.org/stable/modules/linear_model.html#linear-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((50, 1)), x]  # Add bias term (column of 1s)\n",
    "\n",
    "# Compute the best-fit line using the Normal Equation\n",
    "theta_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\n",
    "# Extract slope and intercept\n",
    "c, m = theta_best\n",
    "\n",
    "# Compute predicted y values\n",
    "y_pred = m * x + c\n",
    "\n",
    "print(f\"Trained model: y = {m:.3f}x + {c:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, color=\"orange\", label=\"Closed form predictions\")\n",
    "\n",
    "# Draw vertical lines from each point to the line\n",
    "for i in range(len(x)):\n",
    "    plt.plot([x[i], x[i]], [y[i], y_pred[i]], color='black', linestyle='dashed')\n",
    "\n",
    "plt.title(\"Linear Regression with closed-form predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real world data example\n",
    "\n",
    "Lets use linear regression to solve a small problem. Using GDP per capita, predict a life satisfaction score for a country of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the data\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat_df = pd.read_csv(data_root + \"lifesat/lifesat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y\n",
    "X = lifesat_df[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat_df[[\"Life satisfaction\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifesat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "lifesat_df.plot(\n",
    "    kind=\"scatter\", grid=True, x=\"GDP per capita (USD)\", y=\"Life satisfaction\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a linear model and train it\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction for Cyprus, given GDP is USD 37655.2 in 2020\n",
    "X_new = [[37655.2]]\n",
    "y_pred_new = model.predict(X_new)\n",
    "\n",
    "print(f\"Cyprus predicted life satisfaction: {y_pred_new[0][0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "lifesat_df.plot(\n",
    "    kind=\"scatter\", grid=True, x=\"GDP per capita (USD)\", y=\"Life satisfaction\"\n",
    ")\n",
    "plt.scatter(X_new, y_pred_new, c=\"red\", marker=\"x\", label=\"Cyprus\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression (multiple regression)\n",
    "\n",
    "We have used linear regression in scenarios where we are predicting one dependent variable (i.e. $y$) from one independent variable (i.e. $x$). Linear regression can be used in situations where we are predicting $y$ from two or more independent variables. Mathematically, it is not quite as simple as performing linear regression for each of the independent variables.\n",
    "\n",
    "The general equation for multiple linear regression is:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n + \\epsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y$ = Dependent variable (what we're predicting)\n",
    "- $x_1, x_2, ..., x_n$ = Independent variables (predictors)\n",
    "- $\\beta_0$ = Intercept (value of $y$ when all $x$'s are 0)\n",
    "- $\\beta_1, \\beta_2, ..., \\beta_n$ = Regression coefficients (indicating how much $y$ changes with a unit change in each $x_1, x_2, ..., x_n$ respectively.\n",
    "- $\\epsilon$ = Error term (accounts for variance not explained by the predictors)\n",
    "\n",
    "A simple example might be trying to predict a person's **salary ($y$)** based on their **years of experience ($x_1$)** and **education level ($x_2$)**. The regression equation might look like:\n",
    "\n",
    "$$\n",
    "\\text{Salary} = 30,000 + 5000(\\text{Years of Experience}) + 2000(\\text{Education Level}) + \\epsilon\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple regression with synthetic data\n",
    "\n",
    "As before, we can generate some random data, but this time, for two dependent variables. We will need to combine the feature variables to create a single vector for the model training stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.rand(100, 1) * 10  # First feature\n",
    "X2 = np.random.rand(100, 1) * 10  # Second feature\n",
    "y = 2 * X1 + 2 * X2 + np.random.randn(100, 1) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((X1, X2))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create and train the model as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view coefficients (note there are now two):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But still one intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still make predictions, but we need to provide two samples, and wrangle them a bit more than before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two new samples for x1 and x2\n",
    "x1_new = 5\n",
    "x2_new = 6\n",
    "\n",
    "# Samples in correct shape for model prediction\n",
    "X_new = np.array([[x1_new, x2_new]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new y value from two independent variables\n",
    "y_pred_new = model.predict(X_new)[0][0]\n",
    "\n",
    "print(y_pred_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what is the equivalent plot? For multiple regression, instead of a line of best fit, we can plot a hyperplane. For two X dimensions and one y dimension, this can be plotted exactly on a 3 dimensional X Y Z plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid for the hyperplane\n",
    "X1_range = np.linspace(X1.min(), X1.max(), 20)\n",
    "X2_range = np.linspace(X2.min(), X2.max(), 20)\n",
    "X1_mesh, X2_mesh = np.meshgrid(X1_range, X2_range)\n",
    "\n",
    "# These are our y values\n",
    "y_mesh = model.intercept_ + model.coef_[0][0] * X1_mesh + model.coef_[0][1] * X2_mesh\n",
    "\n",
    "# Create scatter plot of data\n",
    "scatter = go.Scatter3d(\n",
    "    x=X1.flatten(),\n",
    "    y=X2.flatten(),\n",
    "    z=y.flatten(),\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=5, color=\"blue\"),\n",
    "    name=\"Data\",\n",
    ")\n",
    "\n",
    "# Create surface plot of regression plane\n",
    "surface = go.Surface(\n",
    "    x=X1_mesh,\n",
    "    y=X2_mesh,\n",
    "    z=y_mesh,\n",
    "    colorscale=\"viridis\",\n",
    "    opacity=0.5,\n",
    "    name=\"Regression Plane\",\n",
    "    showscale=False\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[scatter, surface])\n",
    "fig.update_layout(\n",
    "    scene=dict(xaxis_title=\"X1\", yaxis_title=\"X2\", zaxis_title=\"Y\"),\n",
    "    title=\"Multiple Regression Hyperplane\",\n",
    ")\n",
    "# You might want to run fig.show() instead of the line below\n",
    "fig.write_html(\"../../_static/multiple_regression_hyperplane.html\", include_plotlyjs=\"cdn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Set the file name for the interactive plot\n",
    "file_name = \"../../_static/multiple_regression_hyperplane.html\"\n",
    "\n",
    "# Generate a unique ID for the iframe\n",
    "iframe_id = \"iframe-multiple_regression_hyperplane\"\n",
    "\n",
    "# Create a display HTML block with a title\n",
    "html_str = \"<div style='text-align: center;'></div>\"\n",
    "html_str += f\"<iframe id='{iframe_id}' src='{file_name}' width='100%' height='750px' style='border:none;'></iframe>\"\n",
    "\n",
    "# Include JavaScript to adjust the iframe height based on its width (if desired)\n",
    "js_code = f\"\"\"\n",
    "<script>\n",
    "function adjustIframeHeight_{iframe_id}() {{\n",
    "    const iframe = document.getElementById('{iframe_id}');\n",
    "    if (iframe) {{\n",
    "        iframe.style.height = iframe.offsetWidth + 'px';\n",
    "    }}\n",
    "}}\n",
    "\n",
    "// Adjust height on load and resize\n",
    "window.onload = adjustIframeHeight_{iframe_id};\n",
    "window.onresize = adjustIframeHeight_{iframe_id};\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "html_str += js_code\n",
    "display(HTML(html_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted y values for the actual data points\n",
    "y_pred = (\n",
    "    model.intercept_\n",
    "    + model.coef_[0][0] * X1.flatten()\n",
    "    + model.coef_[0][1] * X2.flatten()\n",
    ")\n",
    "\n",
    "# Create vertical dashed lines from actual data points to predicted points\n",
    "lines = []\n",
    "for i in range(len(X1.flatten())):\n",
    "    lines.append(\n",
    "        go.Scatter3d(\n",
    "            x=[X1.flatten()[i], X1.flatten()[i]],\n",
    "            y=[X2.flatten()[i], X2.flatten()[i]],\n",
    "            z=[y.flatten()[i], y_pred[i]],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", width=4, dash=\"dash\"),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add extra point (Red marker)\n",
    "extra_point = go.Scatter3d(\n",
    "    x=[x1_new],\n",
    "    y=[x2_new],\n",
    "    z=[y_pred_new],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=8, color=\"red\", symbol=\"diamond\"),\n",
    "    name=\"New Point\",\n",
    ")\n",
    "\n",
    "# Create figure and add all elements\n",
    "fig = go.Figure(data=[scatter, surface, extra_point] + lines)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    scene=dict(xaxis_title=\"X1\", yaxis_title=\"X2\", zaxis_title=\"Y\"),\n",
    "    title=\"Multiple Regression Hyperplane (with vertical residual lines and our added point)\",\n",
    "    showlegend=False,\n",
    ")\n",
    "# You might want to run fig.show() instead of the line below\n",
    "fig.write_html(\"../../_static/multiple_regression_hyperplane_2.html\", include_plotlyjs=\"cdn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Set the file name for the interactive plot\n",
    "file_name = \"../../_static/multiple_regression_hyperplane_2.html\"\n",
    "\n",
    "# Generate a unique ID for the iframe\n",
    "iframe_id = \"iframe-multiple_regression_hyperplane_2\"\n",
    "\n",
    "# Create a display HTML block with a title\n",
    "html_str = \"<div style='text-align: center;'></div>\"\n",
    "html_str += f\"<iframe id='{iframe_id}' src='{file_name}' width='100%' height='750px' style='border:none;'></iframe>\"\n",
    "\n",
    "# Include JavaScript to adjust the iframe height based on its width (if desired)\n",
    "js_code = f\"\"\"\n",
    "<script>\n",
    "function adjustIframeHeight_{iframe_id}() {{\n",
    "    const iframe = document.getElementById('{iframe_id}');\n",
    "    if (iframe) {{\n",
    "        iframe.style.height = iframe.offsetWidth + 'px';\n",
    "    }}\n",
    "}}\n",
    "\n",
    "// Adjust height on load and resize\n",
    "window.onload = adjustIframeHeight_{iframe_id};\n",
    "window.onresize = adjustIframeHeight_{iframe_id};\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "html_str += js_code\n",
    "display(HTML(html_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfrr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
